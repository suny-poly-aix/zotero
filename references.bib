
@online{baek_towards_2025,
	title = {Towards human-centered, open, and social interfaces for {AI}},
	rights = {Copyright is held by the author(s).},
	url = {https://summit.sfu.ca/item/39395},
	abstract = {With growing adoption of {AI} systems, demand increases for interfaces prioritizing user agency, privacy, and extensibility. Proprietary platforms, such as {ChatGPT}, present challenges involving openness, model choice, and user-driven enhancements. Decentralized, open-source interfaces offering locally hosted {AI} provide greater transparency, flexibility, and adaptability. This thesis examines an open-source interface enabling transparent, extensible, and intuitive interaction with privately hosted models. Core design principles emphasizing openness, extensibility, and usability are discussed. Evaluation methods include community engagement analysis via {GitHub} and Discord, and structured user surveys identifying real-world use cases. Findings demonstrate strong user interest in local, self-hosted {AI} due to improved privacy and flexibility. {xAdditionally}, our initial findings suggest the importance of participatory {AI} governance, ethical data handling, and community-driven model evaluation. By exploring mechanisms for crowd-powered auditing and collaborative sharing of {AI} preferences, this thesis contributes to emerging social computing paradigms that promote inclusivity, transparency, and collective intelligence.},
	author = {Baek, Jaeryang},
	urldate = {2025-06-09},
	date = {2025-03-26},
	note = {Publisher: Simon Fraser University},
	file = {Full Text PDF:/Users/itkn/Zotero/storage/CI27Z7KK/Baek - 2025 - Towards human-centered, open, and social interface.pdf:application/pdf},
}

@article{josa_local_2024,
	title = {{LOCAL} {LLMS}: {SAFEGUARDING} {DATA} {PRIVACY} {IN} {THE} {AGE} {OF} {GENERATIVE} {AI}. A {CASE} {STUDY} {AT} {THE} {UNIVERSITY} {OF} {ANDORRA}},
	issn = {2340-1095},
	url = {https://library.iated.org/view/DORCAJOSA2024LOC},
	doi = {10.21125/iceri.2024.1931},
	shorttitle = {{LOCAL} {LLMS}},
	abstract = {The growing field of Generative Artificial Intelligence ({GAI}) presents an unprecedented opportunity for innovation across diverse sectors. The inherent nature of these models, trained on vast amounts of data often sourced from the public domain, raises critical concerns regarding data privacy and security. At the same time, the reliance on centralized servers hosted by large technology companies that have access and utilize these powerful {AI} tools introduces a significant vulnerability. This paper argues about the importance of deploying local Large Language Models ({LLMs}) on on-premise servers to mitigate the risks associated with data leakage to {GAI} providers.

Also, it has to be taken into account that the very act of transmitting data to remote servers inherently introduces security vulnerabilities. Data breaches, cyberattacks, and unauthorized access can compromise the confidentiality of user and company information, potentially leading to identity theft, financial fraud, or other detrimental consequences.

Deploying local {LLMs} on on-premise servers presents a compelling solution to data security and accessibility challenges. The University of Andorra ({UdA}) has implemented a local {LLM} server using open technologies such as Ollama, Open {WebUI}, and Automatic1111. This infrastructure enables the hosting of most small to medium-sized open-source {LLM} models for the teaching and administrative staff community. By retaining both the {AI} model and the processed data within a controlled environment, organizations can establish and guarantee a strong data security framework.

At the same time, local {LLMs} empower organizations to exercise greater control over their data and {AI} capabilities. They can fine tune the model to their specific needs, ensuring alignment with their business objectives and ethical considerations.

Implementation of local {LLMs}, however, is not without its challenges. The initial investment in hardware infrastructure can be substantial, particularly for smaller organizations. Additionally, maintaining and updating local {AI} models requires technical expertise and ongoing resources.

This paper focuses on discussing the pros and cons of this kind of setup as well as the bare minimums needed to host an {LLM} on premises both to ensure the capabilities previously mentioned and, at the same time, ensure a successful user experience. Features like talking with documents or websites using Retrieval Augmented Generation ({RAG}), user data integrity and privacy, or image generation should be within the initial requirements.

Finally, a qualitative survey has been conducted among the teaching and administrative staff at the {UdA} to gather insights and use cases for improving the setup in the future. The results revealed that data privacy and open access are the most valued features, while the quality of responses compared to other private and closed online models is perceived as the least favorable aspect. Despite this, there is promising potential for local implementations of {LLMs}, with plans to extend the service to students in the near future to bridge any accessibility gap they may currently face.},
	pages = {7879--7888},
	journaltitle = {{ICERI}2024 Proceedings},
	author = {Josa, A. Dorca and Bleda-Bejar, M.},
	urldate = {2025-06-09},
	date = {2024},
	langid = {english},
	note = {Conference Name: 17th annual International Conference of Education, Research and Innovation
{ISBN}: 9788409630103
Meeting Name: 17th annual International Conference of Education, Research and Innovation
Place: Seville, Spain
Publisher: {IATED}},
	file = {Dorca Josa and Bleda-Bejar - 2024 - LOCAL LLMS SAFEGUARDING DATA PRIVACY IN THE AGE O.pdf:/Users/itkn/Zotero/storage/K6NJEH62/Dorca Josa and Bleda-Bejar - 2024 - LOCAL LLMS SAFEGUARDING DATA PRIVACY IN THE AGE O.pdf:application/pdf},
}

@misc{hou_unveiling_2025,
	title = {Unveiling the Landscape of {LLM} Deployment in the Wild: An Empirical Study},
	url = {http://arxiv.org/abs/2505.02502},
	doi = {10.48550/arXiv.2505.02502},
	shorttitle = {Unveiling the Landscape of {LLM} Deployment in the Wild},
	abstract = {Background: Large language models ({LLMs}) are increasingly deployed via open-source and commercial frameworks, enabling individuals and organizations to self-host advanced {AI} capabilities. However, insecure defaults and misconfigurations often expose {LLM} services to the public Internet, posing significant security and system engineering risks. Aims: This study aims to unveil the current landscape of public-facing {LLM} deployments in the wild through a large-scale empirical study, focusing on service prevalence, exposure characteristics, systemic vulnerabilities, and associated risks. Method: We conducted an Internet-wide measurement to identify public-facing {LLM} deployments across 15 frameworks, discovering 320,102 services. We extracted 158 unique {API} endpoints, grouped into 12 functional categories based on capabilities and security risks. We further analyzed configurations, authentication practices, and geographic distributions, revealing deployment trends and systemic issues in real-world {LLM} system engineering. Results: Our study shows that public {LLM} deployments are rapidly growing but often insecure. Among all endpoints, we observe widespread use of insecure protocols, poor {TLS} configurations, and unauthenticated access to critical operations. Security risks, including model disclosure, system leakage, and unauthorized access, are pervasive, highlighting the need for secure-by-default frameworks and stronger deployment practices. Conclusions: Public-facing {LLM} deployments suffer from widespread security and configuration flaws, exposing services to misuse, model theft, resource hijacking, and remote exploitation. Strengthening default security, deployment practices, and operational standards is critical for the growing self-hosted {LLM} ecosystem.},
	number = {{arXiv}:2505.02502},
	publisher = {{arXiv}},
	author = {Hou, Xinyi and Han, Jiahao and Zhao, Yanjie and Wang, Haoyu},
	urldate = {2025-06-08},
	date = {2025-05-05},
	eprinttype = {arxiv},
	eprint = {2505.02502 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Software Engineering},
	file = {Preprint PDF:/Users/itkn/Zotero/storage/44MHMGR5/Hou et al. - 2025 - Unveiling the Landscape of LLM Deployment in the W.pdf:application/pdf;Snapshot:/Users/itkn/Zotero/storage/LP3LGTDH/2505.html:text/html},
}

@inproceedings{10.1007/978-3-031-93236-6_17,
	location = {Cham},
	title = {Feasibility and usability practice on local hosting open source large language models (llms) including llama 3.2 vision 90B in multi-functional agentic artificial intelligence ({AI}) system to drive service for design in the latest affordable small personal computer ({PC}) system},
	isbn = {978-3-031-93236-6},
	abstract = {This paper aims to explore feasibility and usability practices from affordable small personal computer ({PC}) for local host of open source Large Language Models ({LLMs}) in multi-functional agentic artificial intelligence ({AI}) system on {AI}-driven services for design via a practice with experimental comparison view. Hence, a practical experiment method has been adopted for evaluating feasibility and usability practices for the local host of the systems. The results suggest that for the adopted three affordable small/mini {PCs}' systems under price of 800 {USD} i.e., a Windows {PC}1 having dedicated graphic card with {GPU} and V-{RAM}, an Apple {macOS} {PC} Mac min m4 with 16GB {RAM}, and a Windows {PC}2 with inbuilt {GPU} and {NPU} with 96GB {RAM}, when {LLMs} models can be fully supported in the {AI} agent and agentic system, graphic generation performance is associated with the power of the graphic card with {GPU} and V-{RAM}, and the chat and vision performance is related to the power of the latest new hardware technologies for {CPU}, {GPU}, {NPU} and {RAM}. The Windows {PC}1 performs the fastest on graphic generation in Flux; and the Apple {macOS} {PC} Mac min m4 with 16GB {RAM} is the best to conducts chat and vision tasks via Msty. Interestingly, only the Windows {PC}2 can execute the biggest Llama3.2 vision 90b model for chat and vision tasks having the similar performance with running on the small Llama3.2-vision: latest 11b model. Moreover, all the three {PCs} can conduct multimodal understanding tasks of the latest Deepseek Janus Pro 7B model, whist in order to perform the tasks of multimodal text-to-image generation, the technical Torch program related issue needs to be addressed in the initial installation stage. Further, all the three {PCs} can local host the complex {AI} agentic systems such as Langflow, Bolt.diy, n8n, Flowise, and Dify with full functions working smoothly in the same conditions for the use of multi-functional production.},
	pages = {261--279},
	booktitle = {Design, user experience, and usability},
	publisher = {Springer Nature Switzerland},
	author = {Liu, Zhen and Wang, Qixu and Lu, Hao and Wang, Yifang},
	editor = {Schrepp, Martin},
	date = {2025},
	file = {Liu et al. - 2025 - Feasibility and usability practice on local hostin.pdf:/Users/itkn/Zotero/storage/S9NA927E/Liu et al. - 2025 - Feasibility and usability practice on local hostin.pdf:application/pdf},
}

@audio{detweiler_rhetoricity_nodate,
	title = {Rhetoricity: {AI} Goes to College: Large Language Models and the Teaching of Writing},
	url = {https://rhetoricity.libsyn.com/2023/08},
	shorttitle = {{AI} Goes to College: Large Language Models and the Teaching of Writing},
	abstract = {Rhetoricity is a quasi-academic podcast that draws on rhetoric, theory, weird sound effects, and the insights of a lot of other people. It's something that's a little strange and, with luck, a little interesting. The podcast's description will evolve along with it. Most episodes feature interviews with rhetoric, composition, and writing studies scholars.

The podcast is a project of Eric Detweiler, director of the Public Writing and Rhetoric program and associate professor in the Department of English at Middle Tennessee State University. If you are interested in more information, you can get in touch by using the contact information included on his website.

Transcripts are available for most episodes. Click "Episode Transcript" link at the end of individual episode descriptions to access the corresponding transcript. If you would like a transcript of an episode that doesn't appear to have one, feel free to get in touch.

Rhetoricity has received support from a grant from the Humanities Media Project.

This podcast is licensed under a Creative Commons Attribution-{NonCommercial} 4.0 International License.},
	author = {Detweiler, Eric},
	urldate = {2025-06-08},
	note = {Issued: 2023-08-23},
	file = {AI_Transcript.pdf:/Users/itkn/Zotero/storage/SIHYL9RK/AI_Transcript.pdf:application/pdf},
}

@article{fatharani_pharmacogenomics_2025,
	title = {Pharmacogenomics Meets Generative {AI}: Transforming Clinical Trial Design with Large Language Models},
	issn = {0976-500X},
	url = {https://doi.org/10.1177/0976500X251321885},
	doi = {10.1177/0976500X251321885},
	shorttitle = {Pharmacogenomics Meets Generative {AI}},
	abstract = {{BackgroundPharmacogenomics} aims to optimise drug therapy based on genetic makeup, but traditional clinical trial design faces challenges with complexity, cost and data integration.{PurposeThis} study explores integrating generative artificial intelligence ({AI}), specifically large language models ({LLMs}) like Llama3 8B, Mistral 7B v0.3 and Phi-3 Mini 3.8B, into pharmacogenomics clinical trial design through Retrieval-Augmented Generation frameworks and local knowledge bases to address the challenges.Materials and {MethodsWe} conducted a comparative analysis of {LLMs}, evaluating the accuracy, relevancy, response time and operational efficiency with a case study that assessed {LLMs}’ capacity to address key trial design elements. The {LLMs} were locally run using an {RTX} 4080 mobile graphics card and Intel Core i9-13980HX central processing unit, with Open-{WebUI} employed.{ResultsOur} results show that Llama3 8B and Phi-3 Mini 3.8B both achieved an accuracy and relevancy score of 0.92 and 0.89, showcasing their underscore of advanced capabilities in delivering both accurate and contextually relevant outputs. More thorough results showed that Phi-3 Mini 3.8B excelled in efficiency and scalability, while Llama3 8B provided greater contextual depth.{ConclusionThis} study indicates that generative {AI} offers transformative potential in pharmacogenomics clinical trials, enhancing efficiency and outcomes. However, challenges such as potential bias and the need for further validation remain. Addressing these limitations and advancing multimodal {AI} capabilities will further support inclusive and effective trial designs.},
	pages = {0976500X251321885},
	journaltitle = {Journal of Pharmacology and Pharmacotherapeutics},
	author = {Fatharani, Annisa and Alsayegh, Ali},
	urldate = {2025-06-05},
	date = {2025-03-01},
	note = {Publisher: {SAGE} Publications},
	file = {SAGE PDF Full Text:/Users/itkn/Zotero/storage/A8T82FKE/Fatharani and Alsayegh - 2025 - Pharmacogenomics Meets Generative AI Transforming.pdf:application/pdf},
}

@incollection{xenakis_llm-based_2025,
	title = {An {LLM}-Based Smart Repository Platform to Support Educators With Computational Thinking, {AI}, and {STEM} Activities},
	rights = {Access limited to members},
	isbn = {979-8-3693-9806-7},
	url = {https://www.igi-global.com/chapter/an-llm-based-smart-repository-platform-to-support-educators-with-computational-thinking-ai-and-stem-activities/www.igi-global.com/chapter/an-llm-based-smart-repository-platform-to-support-educators-with-computational-thinking-ai-and-stem-activities/365565},
	abstract = {In this chapter, we aim to describe the design technology and educational necessity of a smart repository platform, which supports educators with all necessary materials and activities to plan and execute lesson plans, based on computational thinking and {STEM} activities. To this end, our platform pr...},
	pages = {107--136},
	booktitle = {Empowering {STEM} Educators With Digital Tools},
	publisher = {{IGI} Global Scientific Publishing},
	author = {Xenakis, Apostolos and Dimos, Ioanis and Feidakis, Michalis and Sotiropoulos, Dimitrios and Kalovrektis, Konstantinos and Nikolaou, Grigoris},
	urldate = {2025-06-05},
	date = {2025},
	langid = {english},
	doi = {10.4018/979-8-3693-9806-7.ch005},
}

@online{noauthor_empowering_nodate,
	title = {Empowering {STEM} educators with digital tools - {SUNY} Polytechnic Institute},
	url = {https://suny-ins.primo.exlibrisgroup.com},
	abstract = {Empowering {STEM} educators with digital tools-book},
	urldate = {2025-06-05},
	langid = {english},
	file = {Snapshot:/Users/itkn/Zotero/storage/FRPK894Q/openurl.html:text/html},
}

@article{othman_comparative_2024,
	title = {Comparative analysis of {GPT}-4, Gemini, and Ernie as gloss sign language translators in special education},
	volume = {2},
	issn = {2731-9687},
	url = {https://doi.org/10.1007/s44282-024-00113-0},
	doi = {10.1007/s44282-024-00113-0},
	abstract = {While several comparative studies have analyzed the effectiveness of various large language models ({LLMs}), most of them were technical (i.e., comparing execution time, among others). Additionally, these comparative studies did not discuss special education. Consequently, scant information exists about how effective {LLMs} are in special education. To address this research gap, this study conducted a comparative study of three {LLMs}, namely {GPT}-4o, Gemini, and Ernie, as gloss sign language translators for learners with hearing impairments. Specifically, a mixed method was adopted, where the translated outputs of the three {LLMs} were compared (quantitatively and qualitatively) to two sign language outputs from a sign language expert. The obtained results highlighted that Gemini outperformed both {GPT}-4o and Ernie as an accurate gloss sign language translator. Additionally, {GPT}-4o had a high accurate rate, while Ernie had a very low translation performance. The findings of this study can help to raise awareness about the use of {LLMs} in special education as well as the best ones to use especially with hearing impairment learners.},
	pages = {86},
	number = {1},
	journaltitle = {Discover Global Society},
	shortjournal = {Discov glob soc},
	author = {Othman, Achraf and Chemnad, Khansa and Tlili, Ahmed and Da, Ting and Wang, Huanhuan and Huang, Ronghuai},
	urldate = {2025-06-05},
	date = {2024-11-07},
	langid = {english},
	keywords = {{ChatGPT}, Deaf, Ernie, Gemini, Generative {AI}, Gloss sign language, Hearing impairments, Interpreting, Language Policy and Planning, Language Teaching and Learning, Language Translation, Large language models, Sign Languages, Special education, Translation Studies},
	file = {Full Text PDF:/Users/itkn/Zotero/storage/H4BEFG6D/Othman et al. - 2024 - Comparative analysis of GPT-4, Gemini, and Ernie a.pdf:application/pdf},
}

@unpublished{leclerc_howto_2024,
	location = {Gif-sur Yvette, France},
	title = {{HOWTO} install and use {AI} as a tool in research: A focus on bibliographic tools},
	url = {https://hal.science/hal-04755504},
	shorttitle = {{HOWTO} install and use {AI} as a tool in research},
	abstract = {The presentation provides an introduction to local {AI} models by presenting practical demonstrations and elucidating their advantages. A critical examination of their applications in diverse fields follows, highlighting their potential to drive innovation. Additionally, the lecture introduces bibliographic tools that leverage {AI}-powered assistants based on optimized non-local Large Language Models ({LLMs}) to facilitate tasks such as article summarization, information retrieval, and document analysis.},
	type = {Master},
	howpublished = {Master},
	author = {Leclerc, Fabrice},
	urldate = {2025-06-05},
	date = {2024-10},
	note = {Num Pages: 53},
	keywords = {{AI} Model Repository, Bibliographic analysis, Bibliography as topic, {LLM} Large Language Model, Org mode},
	file = {HAL PDF Full Text:/Users/itkn/Zotero/storage/RD284NFQ/Leclerc - 2024 - HOWTO install and use AI as a tool in research A .pdf:application/pdf},
}

@online{noauthor_frame_nodate,
	title = {The Frame of Reference: Solving Detective Stories with {AI} - \#1 {\textbar} Collin Jennings},
	url = {https://share.google/lOF8UDswLFRsdb4FL},
	urldate = {2025-06-05},
}

@online{noauthor_teaching_nodate,
	title = {Teaching Repository of {AI}-Infused Learning {\textbar} University of Central Florida},
	url = {https://stars.library.ucf.edu/traiil/},
	urldate = {2025-06-03},
	file = {Teaching Repository of AI-Infused Learning | University of Central Florida:/Users/itkn/Zotero/storage/CD3KMSKY/traiil.html:text/html},
}

@online{noauthor_open_nodate,
	title = {Open {WebUI} Course - {DigitalBrainBase}},
	url = {https://www.digitalbrainbase.com/c/open-webui/8},
	urldate = {2025-06-03},
}

@article{von_garrel_artificial_2023,
	title = {Artificial Intelligence in studies—use of {ChatGPT} and {AI}-based tools among students in Germany},
	volume = {10},
	rights = {2023 The Author(s)},
	issn = {2662-9992},
	url = {https://www.nature.com/articles/s41599-023-02304-7},
	doi = {10.1057/s41599-023-02304-7},
	abstract = {{AI}-based tools such as {ChatGPT} and {GPT}-4 are currently changing the university landscape and in many places, the consequences for future forms of teaching and examination are already being discussed. In order to create an empirical basis for this, a nationwide survey of students was carried out in order to analyse the use and possible characteristics of {AI}-based tools that are important to students. The aim of the quantitative study is to be able to draw conclusions about how students use such {AI} tools. A total of more than 6300 students across Germany took part in the anonymous survey. The results of this quantitative analysis make it clear that almost two-thirds of the students surveyed use or have used {AI}-based tools as part of their studies. In this context, almost half of the students explicitly mention {ChatGPT} or {GPT}-4 as a tool they use. Students of engineering sciences, mathematics and natural sciences use {AI}-based tools most frequently. A differentiated examination of the usage behaviour makes it clear that students use {AI}-based tools in a variety of ways. Clarifying questions of understanding and explaining subject-specific concepts are the most relevant reasons for use in this context.},
	pages = {1--9},
	number = {1},
	journaltitle = {Humanities and Social Sciences Communications},
	shortjournal = {Humanit Soc Sci Commun},
	author = {von Garrel, Jörg and Mayer, Jana},
	urldate = {2025-06-09},
	date = {2023-11-09},
	langid = {english},
	note = {Publisher: Palgrave},
	keywords = {Education, Information systems and information technology, Science, technology and society},
	file = {Full Text PDF:/Users/itkn/Zotero/storage/HBHSIQM9/von Garrel and Mayer - 2023 - Artificial Intelligence in studies—use of ChatGPT and AI-based tools among students in Germany.pdf:application/pdf},
}

@online{noauthor_ai_nodate,
	title = {{AI} Verde {\textbar} Data Science Institute},
	url = {https://datascience.arizona.edu/research/tools/ai-verde},
	urldate = {2025-06-10},
	langid = {english},
	file = {Snapshot:/Users/itkn/Zotero/storage/6TE85NA5/ai-verde.html:text/html},
}

@misc{mithun_ai-verde_2025,
	title = {{AI}-{VERDE}: A Gateway for Egalitarian Access to Large Language Model-Based Resources For Educational Institutions},
	url = {http://arxiv.org/abs/2502.09651},
	doi = {10.48550/arXiv.2502.09651},
	shorttitle = {{AI}-{VERDE}},
	abstract = {We present {AI}-{VERDE}, a unified {LLM}-as-a-platform service designed to facilitate seamless integration of commercial, cloud-hosted, and on-premise open {LLMs} in academic settings. {AI}-{VERDE} streamlines access management for instructional and research groups by providing features such as robust access control, privacy-preserving mechanisms, native Retrieval-Augmented Generation ({RAG}) support, budget management for third-party {LLM} services, and both a conversational web interface and {API} access. In a pilot deployment at a large public university, {AI}-{VERDE} demonstrated significant engagement across diverse educational and research groups, enabling activities that would typically require substantial budgets for commercial {LLM} services with limited user and team management capabilities. To the best of our knowledge, {AI}-Verde is the first platform to address both academic and research needs for {LLMs} within an higher education institutional framework.},
	number = {{arXiv}:2502.09651},
	publisher = {{arXiv}},
	author = {Mithun, Paul and Noriega-Atala, Enrique and Merchant, Nirav and Skidmore, Edwin},
	urldate = {2025-06-10},
	date = {2025-02-11},
	eprinttype = {arxiv},
	eprint = {2502.09651 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society},
	file = {Preprint PDF:/Users/itkn/Zotero/storage/G64JAHJC/Mithun et al. - 2025 - AI-VERDE A Gateway for Egalitarian Access to Larg.pdf:application/pdf;Snapshot:/Users/itkn/Zotero/storage/W9WSQ7HD/2502.html:text/html},
}

@inproceedings{bender_dangers_2021,
	location = {New York, {NY}, {USA}},
	title = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜},
	isbn = {978-1-4503-8309-7},
	url = {https://dl.acm.org/doi/10.1145/3442188.3445922},
	doi = {10.1145/3442188.3445922},
	series = {{FAccT} '21},
	shorttitle = {On the Dangers of Stochastic Parrots},
	abstract = {The past 3 years of work in {NLP} have been characterized by the development and deployment of ever larger language models, especially for English. {BERT}, its variants, {GPT}-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
	pages = {610--623},
	publisher = {Association for Computing Machinery},
	author = {Bender, Emily M. and Gebru, Timnit and {McMillan}-Major, Angelina and Shmitchell, Shmargaret},
	urldate = {2025-06-09},
	date = {2021-03-01},
	file = {PDF:/Users/itkn/Zotero/storage/2N362XF2/Bender et al. - 2021 - On the Dangers of Stochastic Parrots Can Language Models Be Too Big ?.pdf:application/pdf},
}

@inproceedings{zheng_webolympus_2024,
	location = {Miami, Florida, {USA}},
	title = {{WebOlympus}: An Open Platform for Web Agents on Live Websites},
	url = {https://aclanthology.org/2024.emnlp-demo.20/},
	doi = {10.18653/v1/2024.emnlp-demo.20},
	shorttitle = {{WebOlympus}},
	abstract = {Web agents are emerging as powerful tools capable of performing complex tasks across diverse web environments. The rapid development of large multimodal models is further enhancing this advancement. However, there is a lack of standardized and user-friendly tools for research and development, as well as experimental platforms on live websites. To address this challenge, we present {WebOlympus}, an open platform for web agents operating on live websites. {WebOlympus} offers a Chrome extension-based {UI}, enabling users without programming experience to easily utilize the platform. It allows users to run web agents with various designs using only a few lines of code or simple clicks on the Chrome extension. To ensure the trustworthiness of web agents, a safety monitor module that prevents harmful actions through human supervision or model-based control is incorporated. {WebOlympus} supports diverse applications, including annotation interfaces for web agent trajectories and data crawling.},
	pages = {187--197},
	booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
	publisher = {Association for Computational Linguistics},
	author = {Zheng, Boyuan and Gou, Boyu and Salisbury, Scott and Du, Zheng and Sun, Huan and Su, Yu},
	editor = {Hernandez Farias, Delia Irazu and Hope, Tom and Li, Manling},
	urldate = {2025-06-11},
	date = {2024-11},
	file = {Full Text PDF:/Users/itkn/Zotero/storage/FEA8EER7/Zheng et al. - 2024 - WebOlympus An Open Platform for Web Agents on Liv.pdf:application/pdf},
}

@article{noauthor_designing_nodate,
	title = {Designing an open-source {LLM} interface and social platforms for collectively driven {LLM} evaluation and auditing},
	langid = {english},
	file = {PDF:/Users/itkn/Zotero/storage/59UW72XD/Designing an open-source LLM interface and social platforms for collectively driven LLM evaluation a.pdf:application/pdf},
}

@article{agrawal_running_2025,
	title = {Running {LLMs} Locally on Consumer Devices},
	volume = {13},
	issn = {23219653},
	url = {https://www.ijraset.com/best-journal/running-llms-locally-on-consumer-devices},
	doi = {10.22214/ijraset.2025.69433},
	abstract = {The paper explores practical deployment of large language models ({LLMs}) on consumer-grade hardware, driven by improvements in model efficiency and optimization. It reviews recent open-source {LLMs} that are both powerful and resourceefficient, outlines the hardware and software needed for local execution, and highlights key techniques like quantization and acceleration libraries. The study compares local versus cloud-based deployment in terms of speed, cost, energy use, and privacy. It finds that advanced open models can now run on high-end {PCs}, while smaller versions work well on mainstream setups, though challenges like hardware limits and energy demands remain.},
	pages = {5433--5441},
	number = {4},
	journaltitle = {International Journal for Research in Applied Science and Engineering Technology},
	shortjournal = {{IJRASET}},
	author = {Agrawal, Prof. Pallavi},
	urldate = {2025-06-16},
	date = {2025-04-30},
	langid = {english},
	file = {PDF:/Users/itkn/Zotero/storage/NN4HZHMB/Agrawal - 2025 - Running LLMs Locally on Consumer Devices.pdf:application/pdf},
}

@online{noauthor_demystifying_nodate,
	title = {Demystifying Issues, Causes and Solutions in {LLM} Open-Source Projects},
	url = {https://arxiv.org/html/2409.16559v2},
	urldate = {2025-06-16},
	file = {Demystifying Issues, Causes and Solutions in LLM Open-Source Projects:/Users/itkn/Zotero/storage/B95YT5KR/2409.html:text/html},
}

@misc{lan_benchmarking_2025,
	title = {Benchmarking and Advancing Large Language Models for Local Life Services},
	url = {http://arxiv.org/abs/2506.02720},
	doi = {10.48550/arXiv.2506.02720},
	abstract = {Large language models ({LLMs}) have exhibited remarkable capabilities and achieved significant breakthroughs across various domains, leading to their widespread adoption in recent years. Building on this progress, we investigate their potential in the realm of local life services. In this study, we establish a comprehensive benchmark and systematically evaluate the performance of diverse {LLMs} across a wide range of tasks relevant to local life services. To further enhance their effectiveness, we explore two key approaches: model fine-tuning and agent-based workflows. Our findings reveal that even a relatively compact 7B model can attain performance levels comparable to a much larger 72B model, effectively balancing inference cost and model capability. This optimization greatly enhances the feasibility and efficiency of deploying {LLMs} in real-world online services, making them more practical and accessible for local life applications.},
	number = {{arXiv}:2506.02720},
	publisher = {{arXiv}},
	author = {Lan, Xiaochong and Feng, Jie and Lei, Jiahuan and Shi, Xinlei and Li, Yong},
	urldate = {2025-06-16},
	date = {2025-06-03},
	eprinttype = {arxiv},
	eprint = {2506.02720 [cs]},
	note = {version: 1},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Full Text PDF:/Users/itkn/Zotero/storage/55DV74ZK/Lan et al. - 2025 - Benchmarking and Advancing Large Language Models for Local Life Services.pdf:application/pdf;Snapshot:/Users/itkn/Zotero/storage/NFNHWJ5U/2506.html:text/html},
}

@article{othman_comparative_2024-1,
	title = {Comparative analysis of {GPT}-4, Gemini, and Ernie as gloss sign language translators in special education},
	volume = {2},
	issn = {2731-9687},
	url = {https://doi.org/10.1007/s44282-024-00113-0},
	doi = {10.1007/s44282-024-00113-0},
	abstract = {While several comparative studies have analyzed the effectiveness of various large language models ({LLMs}), most of them were technical (i.e., comparing execution time, among others). Additionally, these comparative studies did not discuss special education. Consequently, scant information exists about how effective {LLMs} are in special education. To address this research gap, this study conducted a comparative study of three {LLMs}, namely {GPT}-4o, Gemini, and Ernie, as gloss sign language translators for learners with hearing impairments. Specifically, a mixed method was adopted, where the translated outputs of the three {LLMs} were compared (quantitatively and qualitatively) to two sign language outputs from a sign language expert. The obtained results highlighted that Gemini outperformed both {GPT}-4o and Ernie as an accurate gloss sign language translator. Additionally, {GPT}-4o had a high accurate rate, while Ernie had a very low translation performance. The findings of this study can help to raise awareness about the use of {LLMs} in special education as well as the best ones to use especially with hearing impairment learners.},
	pages = {86},
	number = {1},
	journaltitle = {Discover Global Society},
	shortjournal = {Discov glob soc},
	author = {Othman, Achraf and Chemnad, Khansa and Tlili, Ahmed and Da, Ting and Wang, Huanhuan and Huang, Ronghuai},
	urldate = {2025-06-16},
	date = {2024-11-07},
	langid = {english},
	keywords = {{ChatGPT}, Deaf, Ernie, Gemini, Generative {AI}, Gloss sign language, Hearing impairments, Interpreting, Language Policy and Planning, Language Teaching and Learning, Language Translation, Large language models, Sign Languages, Special education, Translation Studies},
}

@online{noauthor_howto_nodate,
	title = {{HOWTO} install and use {AI} as a tool in research: A focus on bibliographic tools - Archive ouverte {HAL}},
	url = {https://hal.science/hal-04755504v1/preview/ai_bgbs.pdf#page=2},
	urldate = {2025-06-16},
}

@online{noauthor_timothy_nodate,
	title = {Timothy J. Baek - Why I’m Building Open {WebUI}: On Autonomy, Diversity, and the Future of Humanity},
	url = {https://jryng.com/thoughts/why-open-webui},
	urldate = {2025-06-16},
	file = {Timothy J. Baek - Why I’m Building Open WebUI\: On Autonomy, Diversity, and the Future of Humanity:/Users/itkn/Zotero/storage/I8VDBH44/why-open-webui.html:text/html},
}

@book{marcondes_natural_2025,
	title = {Natural Language Analytics with Generative Large-Language Models: A Practical Approach with Ollama and Open-Source {LLMs}},
	isbn = {978-3-031-76631-2},
	shorttitle = {Natural Language Analytics with Generative Large-Language Models},
	abstract = {This book explores the application of generative Large Language Models ({LLMs}) for extracting and analyzing data from natural language artefacts. Unlike traditional uses of {LLMs}, such as translation and summarization, this book focuses on utilizing these models to convert unstructured text into data that can be processed through the data science pipeline to generate actionable insights. The content is designed for professionals in diverse fields including cognitive science, linguistics, management, and information systems. It combines insights from both industry and academia to provide a comprehensive understanding of how {LLMs} can be effectively used for natural language analytics ({NLA}). The book details practical methodologies for implementing {LLMs} locally using open-source tools, ensuring data privacy and feasibility without the need for expensive infrastructure. Key topics include interpretant, mindset and cultural analysis, emphasizing the use of {LLMs} to derive soft data—qualitative information crucial for nuanced decision-making. The text also outlines the technical aspects of {LLMs}, including their architecture, token embeddings, and the differences between encoder-based and decoder-based models. By providing a case study and practical examples, the authors show how {LLMs} can be used to meet various analytical needs, making this book a valuable resource for anyone looking to integrate advanced natural language processing techniques into their data analysis workflows.},
	pagetotal = {94},
	publisher = {Springer Nature},
	author = {Marcondes, Francisco S. and Gala, Adelino and Magalhães, Renata and Britto, Fernando Perez de and Durães, Dalila and Novais, Paulo},
	date = {2025-02-13},
	langid = {english},
	note = {Google-Books-{ID}: {sHxGEQAAQBAJ}},
	keywords = {Business \& Economics / Business Mathematics, Computers / Artificial Intelligence / General, Computers / Artificial Intelligence / Natural Language Processing, Computers / Business \& Productivity Software / Business Intelligence, Computers / Database Administration \& Management, Computers / Information Technology, Computers / Speech \& Audio Processing, Language Arts \& Disciplines / Linguistics / General, Mathematics / Probability \& Statistics / General},
	file = {quote-about-openwebui:/Users/itkn/Zotero/storage/Z4YMPMZY/quote-about-openwebui.png:image/png},
}

@inproceedings{ishihara_facilitation_2024,
	title = {Facilitation of Kansei engineering design process with {LLM} multi-agent discussion},
	volume = {145},
	isbn = {978-1-964867-21-2},
	url = {https://openaccess.cms-conferences.org/publications/book/978-1-964867-21-2/article/978-1-964867-21-2_0},
	doi = {10.54941/ahfe1005135},
	abstract = {Recent advances in Large Language Models and Generative {AI} continue to have a positive impact on the design process and Kansei engineering.At {AHFE} 2023, we presented the trials of product design using Generative {AI} based on Kansei engineering (Ishihara, Kuo \& Ishihara, {AI} image generation boosts Kansei engineering design process, 2023).In this study, we explored the possibilities of multi-agent discussion in the design process and Kansei engineering.  {GPT}-4 ({OpenAI}) was asked to create experts and discuss the given topic from each expert's point of view. In the example below, the topic was given as "We would like to discuss the design of an innovative chair made with a 3D printer. We would like to hear opinions from as many different perspectives as possible.{GPT}-4 automatically creates 3 virtual experts as: a designer, an engineer, and an environmental specialist. These different experts were created without any specific direction.The following lines are the roles of the experts set up in {GPT}-4: Designer - Focuses the discussion from an aesthetic point of view. Emphasizes innovation and aesthetics in design. Passionate in tone and fond of creative ideas.Engineer - Focuses on practicality and technical feasibility. Discusses cost and material efficiency in detail. Analytical in tone and logical in approach.Environmentalist - Focuses on sustainability and environmental impact. Discusses the use of recyclable materials and reducing environmental impact. They are soft-spoken and have deep insight into environmental issues.Intermediate discussions are in the following lines;---Persona 1: {DesignerInspired} by the engineer's opinion, I'd like to think a little more about the balance between durability and design. Durability is very important because chairs are used on a daily basis, and the key to manufacturing with a 3D printer is ensuring structural strength while still maintaining an aesthetically pleasing design. This can be seen as a design challenge.Persona 3: Environmental {SpecialistI} agree with the designer's suggestion, but materials should be carefully chosen to minimize environmental impact. Environmentally friendly materials, such as bioplastics, can provide greater design freedom while ensuring sustainability. The energy efficiency of the 3D printer is also important.Persona 2: {EngineerI} agree with the points made by the environmental experts. However, when using environmentally friendly materials, one must also pay attention to the physical properties of these materials. It is important to choose materials that are sustainable while still meeting the basic performance requirements of the chair, such as strength and heat resistance.Persona 1: {DesignerThe} engineer's technical perspective is very important. As a designer, the challenge is how to turn these technical limitations into art. For example, if there is a limit to the strength of a material, we can incorporate that as part of the design. I think balancing the flexibility of the design with the technical requirements will be key to the success of this project.The final agenda is as follows;---Designer's {PerspectiveDesign} Innovation: 3D printing allows for unique shapes and patterns that were previously impossible.Aesthetics and Individuality: Aesthetically pleasing designs that match consumer tastes and contemporary interior trends are important.Appealing to consumer sensibilities: Unique and beautiful designs can serve as status symbols, making them feel worth the high price tag.Engineer's {PerspectivePracticality} and technical feasibility: Consider the balance between manufacturing efficiency and cost while maintaining durability and safety.Customization and Quality: Ensure long-term cost-effectiveness and satisfaction by allowing adjustments to accommodate each individual's body shape and preferences.Overcoming technical limitations: Consider the physical limitations of 3D printing technology as part of the design.Environmental {ExpertiseSustainability}: Consider the use of recyclable materials and the recyclability of the product.Environmental impact: Energy consumption and material choices during the manufacturing process are important.Appealing to eco-conscious consumers: Green products add value and justify a price premium.---This is a summary of the discussion on the design of 3D-printed chairs from each expert's perspective. A balance between design innovation, technical feasibility, and sustainability is important, and a product based on these factors will influence consumer purchase incentives and can be successful in the marketplace, even at a high price point.We are now trying to combine this with Generative Graphics {AI} to visualize ideas based on this discussion among virtual experts.},
	eventtitle = {{AHFE} (2024) International Conference},
	booktitle = {Kansei Engineering},
	publisher = {{AHFE} Open Acces},
	author = {Ishihara, Shigekazu and Ishihara, Taku and Ishihara, Keiko},
	urldate = {2025-06-16},
	date = {2024},
	note = {{ISSN}: 27710718
Issue: 145},
}

@incollection{smith_notitle_2025,
	isbn = {978-3-031-93567-1},
	abstract = {The three-volume set {LNCS} 15806–15808 constitutes the thoroughly refereed proceedings of the 12th International Conference on Learning and Collaboration Technologies, {LCT} 2025, held as part of the 27th International Conference, {HCI} International 2025, which took place in Gothenburg, Sweden, June 22-17, 2025. The total of 1430 papers and 355 posters included in the {HCII} 2025 proceedings was carefully reviewed and selected from 7972 submissions. The papers have been organized in topical sections as follows: Part I: Designing Learning Experiences; Technological Innovation in {EducationPart} {II}: From Human Teachers to {AI} Educators; Intelligent Learning Environments Part {III}: Serious Games and Gamification; Immersive Learning; Understanding Learning Experiences},
	booktitle = {Learning and Collaboration Technologies: 12th International Conference, {LCT} 2025, Held as Part of the 27th {HCI} International Conference, {HCII} 2025, Gothenburg, Sweden, June 22–27, 2025, Proceedings, Part {II}},
	publisher = {Springer Nature},
	author = {Smith, Brian K. and Borge, Marcela},
	date = {2025-05-31},
	langid = {english},
	note = {Google-Books-{ID}: {rSliEQAAQBAJ}},
	keywords = {Computers / Artificial Intelligence / General, Business \& Economics / E-Commerce / General, Computers / Business \& Productivity Software / General, Computers / Desktop Applications / General, Computers / Electronic Commerce, Computers / Human-Computer Interaction ({HCI}), Computers / Networking / General, Computers / Networking / Hardware, Computers / Operating Systems / General, Computers / User Interfaces, Education / Computers \& Technology},
}

@online{openwebui_im_2025,
	title = {I’m the Maintainer (and Team) behind Open {WebUI} – {AMA} 2025 Q2},
	url = {https://www.reddit.com/r/OpenWebUI/comments/1l9nkvk/im_the_maintainer_and_team_behind_open_webui_ama/},
	titleaddon = {r/{OpenWebUI}},
	type = {Reddit Post},
	author = {openwebui},
	urldate = {2025-06-17},
	date = {2025-06-12},
	file = {Snapshot:/Users/itkn/Zotero/storage/YC7GBAU6/im_the_maintainer_and_team_behind_open_webui_ama.html:text/html},
}

@online{openwebui_im_2025-1,
	title = {I’m the Maintainer (and Team) behind Open {WebUI} – {AMA} 2025 Q2},
	url = {https://www.reddit.com/r/OpenWebUI/comments/1l9nkvk/im_the_maintainer_and_team_behind_open_webui_ama/},
	titleaddon = {r/{OpenWebUI}},
	type = {Reddit Post},
	author = {openwebui},
	urldate = {2025-06-17},
	date = {2025-06-12},
	file = {Snapshot:/Users/itkn/Zotero/storage/VF5G5YSH/im_the_maintainer_and_team_behind_open_webui_ama.html:text/html},
}

@online{noauthor_facet_nodate,
	title = {{FACET} Framework – {RAIL} {\textbar} Responsible {AI} Lab},
	url = {https://rail.knust.edu.gh/facet-framework/},
	urldate = {2025-06-17},
}

@online{verma_rail_2025,
	title = {{RAIL} in the Wild: Operationalizing Responsible {AI} Evaluation Using Anthropic's Value Dataset},
	url = {https://arxiv.org/abs/2505.00204v1},
	shorttitle = {{RAIL} in the Wild},
	abstract = {As {AI} systems become embedded in real-world applications, ensuring they meet ethical standards is crucial. While existing {AI} ethics frameworks emphasize fairness, transparency, and accountability, they often lack actionable evaluation methods. This paper introduces a systematic approach using the Responsible {AI} Labs ({RAIL}) framework, which includes eight measurable dimensions to assess the normative behavior of large language models ({LLMs}). We apply this framework to Anthropic's "Values in the Wild" dataset, containing over 308,000 anonymized conversations with Claude and more than 3,000 annotated value expressions. Our study maps these values to {RAIL} dimensions, computes synthetic scores, and provides insights into the ethical behavior of {LLMs} in real-world use.},
	titleaddon = {{arXiv}.org},
	author = {Verma, Sumit and Prasun, Pritam and Jaiswal, Arpit and Kumar, Pritish},
	urldate = {2025-06-19},
	date = {2025-04-30},
	langid = {english},
	file = {Full Text PDF:/Users/itkn/Zotero/storage/YITENBYQ/Verma et al. - 2025 - RAIL in the Wild Operationalizing Responsible AI .pdf:application/pdf},
}

@article{verma_rail_nodate,
	title = {{RAIL} in the Wild: Operationalizing Responsible {AI} Evaluation Using Anthropic’s Value Dataset},
	abstract = {As {AI} systems grow increasingly embedded in real-world applications, ensuring that these systems uphold ethical standards is paramount. Existing {AI} ethics frameworks emphasize principles such as fairness, transparency, and accountability, yet they often lack actionable methods for evaluation. In this paper, we introduce a systematic approach using the Responsible {AI} Labs ({RAIL}) framework—comprising eight measurable dimensions—to assess normative behavior of large language models ({LLMs}). We demonstrate its applicability on Anthropic’s “Values in the Wild” [5] dataset, which contains over 308,000 anonymized conversations with Claude, annotated with over 3,000 value expressions. Our study presents a mapping between annotated {AI} values and {RAIL} dimensions, computes synthetic scores across conversations, and offers a diagnostic lens into the ethical behavior of {LLMs} in real-world contexts.},
	author = {Verma, Sumit and Prasun, Pritam and Jaiswal, Arpit and Kumar, Pritish},
	langid = {english},
	file = {Verma et al. - RAIL in the Wild Operationalizing Responsible AI .pdf:/Users/itkn/Zotero/storage/J6A82Q9I/Verma et al. - RAIL in the Wild Operationalizing Responsible AI .pdf:application/pdf},
}

@article{akomea-frimpong_publicprivate_2023,
	title = {Public–private partnerships for sustainable infrastructure development in Ghana: a systematic review and recommendations},
	volume = {12},
	rights = {https://www.emerald.com/insight/site-policies},
	issn = {2046-6099},
	url = {https://www.emerald.com/insight/content/doi/10.1108/SASBE-07-2021-0111/full/html},
	doi = {10.1108/SASBE-07-2021-0111},
	shorttitle = {Public–private partnerships for sustainable infrastructure development in Ghana},
	abstract = {Purpose – The contribution of the public–private partnership ({PPP}) model towards the achievement of the United Nation ({UN})’s Sustainable Development Goals ({SDGs}) has been widely acknowledged. However, limited studies have shed light on the connection between {PPPs} and the achievement of these coveted goals in Ghana. In this study, the authors aimed at analysing and synthesising the existing literature on the use of {PPP} to achieve sustainability in infrastructure projects in the country.},
	pages = {237--257},
	number = {2},
	journaltitle = {Smart and Sustainable Built Environment},
	shortjournal = {{SASBE}},
	author = {Akomea-Frimpong, Isaac and Jin, Xiaohua and Osei-Kyei, Robert and Kukah, Augustine Senanu},
	urldate = {2025-06-19},
	date = {2023-02-20},
	langid = {english},
	file = {Akomea-Frimpong et al. - 2023 - Public–private partnerships for sustainable infras.pdf:/Users/itkn/Zotero/storage/MSE78ARN/Akomea-Frimpong et al. - 2023 - Public–private partnerships for sustainable infras.pdf:application/pdf},
}

@online{noauthor_rail_nodate,
	title = {{RAIL} {\textbar} {FACETS} Responsible {AI} Framework},
	url = {https://facets.netlify.app/},
	urldate = {2025-06-19},
	file = {RAIL | FACETS Responsible AI Framework:/Users/itkn/Zotero/storage/KP944WQQ/facets.netlify.app.html:text/html},
}
